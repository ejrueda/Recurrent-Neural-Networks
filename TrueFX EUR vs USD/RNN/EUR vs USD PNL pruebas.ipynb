{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('../../data/TrueFX/EUR-USD/datos_procesados_OHLC_5T_EURUSD-2018-01.csv', index_col=0,\n",
    "                      infer_datetime_format=True, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:00:00</th>\n",
       "      <td>1.20094</td>\n",
       "      <td>1.20094</td>\n",
       "      <td>1.20011</td>\n",
       "      <td>1.20015</td>\n",
       "      <td>1.20110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:05:00</th>\n",
       "      <td>1.20015</td>\n",
       "      <td>1.20062</td>\n",
       "      <td>1.20011</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:10:00</th>\n",
       "      <td>1.20039</td>\n",
       "      <td>1.20098</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:15:00</th>\n",
       "      <td>1.20080</td>\n",
       "      <td>1.20097</td>\n",
       "      <td>1.20025</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:20:00</th>\n",
       "      <td>1.20034</td>\n",
       "      <td>1.20057</td>\n",
       "      <td>1.20031</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low      bid      ask\n",
       "2018-01-02 00:00:00  1.20094  1.20094  1.20011  1.20015  1.20110\n",
       "2018-01-02 00:05:00  1.20015  1.20062  1.20011  1.20047  1.20084\n",
       "2018-01-02 00:10:00  1.20039  1.20098  1.20035  1.20082  1.20126\n",
       "2018-01-02 00:15:00  1.20080  1.20097  1.20025  1.20035  1.20091\n",
       "2018-01-02 00:20:00  1.20034  1.20057  1.20031  1.20049  1.20085"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../code/PNLEstimatorWrapper.py\n",
    "%run ../../code/EUtilities.py\n",
    "EU = EUtilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = 10\n",
    "X, y_reg, bt = EU.build_dataset(data_set, window=window, bid_col='bid', binary_target=True, PNL=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>PNL_0</th>\n",
       "      <th>PNL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:45:00</th>\n",
       "      <td>1.20015</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>-0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:50:00</th>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>-0.00028</td>\n",
       "      <td>-0.00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:55:00</th>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>0.00071</td>\n",
       "      <td>-0.00103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:00:00</th>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>1.20058</td>\n",
       "      <td>-0.00044</td>\n",
       "      <td>0.00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:05:00</th>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>1.20058</td>\n",
       "      <td>1.20085</td>\n",
       "      <td>-0.00011</td>\n",
       "      <td>-0.00015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0        1        2        3        4        5  \\\n",
       "2018-01-02 00:45:00  1.20015  1.20047  1.20082  1.20035  1.20049  1.20047   \n",
       "2018-01-02 00:50:00  1.20047  1.20082  1.20035  1.20049  1.20047  1.20079   \n",
       "2018-01-02 00:55:00  1.20082  1.20035  1.20049  1.20047  1.20079  1.20135   \n",
       "2018-01-02 01:00:00  1.20035  1.20049  1.20047  1.20079  1.20135  1.20143   \n",
       "2018-01-02 01:05:00  1.20049  1.20047  1.20079  1.20135  1.20143  1.20149   \n",
       "\n",
       "                           6        7        8        9    PNL_0    PNL_1  \n",
       "2018-01-02 00:45:00  1.20079  1.20135  1.20143  1.20149 -0.00007 -0.00030  \n",
       "2018-01-02 00:50:00  1.20135  1.20143  1.20149  1.20133 -0.00028 -0.00017  \n",
       "2018-01-02 00:55:00  1.20143  1.20149  1.20133  1.20139  0.00071 -0.00103  \n",
       "2018-01-02 01:00:00  1.20149  1.20133  1.20139  1.20058 -0.00044  0.00017  \n",
       "2018-01-02 01:05:00  1.20133  1.20139  1.20058  1.20085 -0.00011 -0.00015  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['open'] = data_set.filter(X.index,axis=0).open\n",
    "X['high'] = data_set.filter(X.index,axis=0).high\n",
    "X['low'] = data_set.filter(X.index,axis=0).low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>PNL_0</th>\n",
       "      <th>PNL_1</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:45:00</th>\n",
       "      <td>1.20015</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>-0.00030</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20150</td>\n",
       "      <td>1.20134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:50:00</th>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>-0.00028</td>\n",
       "      <td>-0.00017</td>\n",
       "      <td>1.20150</td>\n",
       "      <td>1.20150</td>\n",
       "      <td>1.20131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:55:00</th>\n",
       "      <td>1.20082</td>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>0.00071</td>\n",
       "      <td>-0.00103</td>\n",
       "      <td>1.20130</td>\n",
       "      <td>1.20142</td>\n",
       "      <td>1.20130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:00:00</th>\n",
       "      <td>1.20035</td>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>1.20058</td>\n",
       "      <td>-0.00044</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>1.20138</td>\n",
       "      <td>1.20155</td>\n",
       "      <td>1.20022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:05:00</th>\n",
       "      <td>1.20049</td>\n",
       "      <td>1.20047</td>\n",
       "      <td>1.20079</td>\n",
       "      <td>1.20135</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20149</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>1.20058</td>\n",
       "      <td>1.20085</td>\n",
       "      <td>-0.00011</td>\n",
       "      <td>-0.00015</td>\n",
       "      <td>1.20060</td>\n",
       "      <td>1.20100</td>\n",
       "      <td>1.20058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0        1        2        3        4        5  \\\n",
       "2018-01-02 00:45:00  1.20015  1.20047  1.20082  1.20035  1.20049  1.20047   \n",
       "2018-01-02 00:50:00  1.20047  1.20082  1.20035  1.20049  1.20047  1.20079   \n",
       "2018-01-02 00:55:00  1.20082  1.20035  1.20049  1.20047  1.20079  1.20135   \n",
       "2018-01-02 01:00:00  1.20035  1.20049  1.20047  1.20079  1.20135  1.20143   \n",
       "2018-01-02 01:05:00  1.20049  1.20047  1.20079  1.20135  1.20143  1.20149   \n",
       "\n",
       "                           6        7        8        9    PNL_0    PNL_1  \\\n",
       "2018-01-02 00:45:00  1.20079  1.20135  1.20143  1.20149 -0.00007 -0.00030   \n",
       "2018-01-02 00:50:00  1.20135  1.20143  1.20149  1.20133 -0.00028 -0.00017   \n",
       "2018-01-02 00:55:00  1.20143  1.20149  1.20133  1.20139  0.00071 -0.00103   \n",
       "2018-01-02 01:00:00  1.20149  1.20133  1.20139  1.20058 -0.00044  0.00017   \n",
       "2018-01-02 01:05:00  1.20133  1.20139  1.20058  1.20085 -0.00011 -0.00015   \n",
       "\n",
       "                        open     high      low  \n",
       "2018-01-02 00:45:00  1.20143  1.20150  1.20134  \n",
       "2018-01-02 00:50:00  1.20150  1.20150  1.20131  \n",
       "2018-01-02 00:55:00  1.20130  1.20142  1.20130  \n",
       "2018-01-02 01:00:00  1.20138  1.20155  1.20022  \n",
       "2018-01-02 01:05:00  1.20060  1.20100  1.20058  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6229, 15), (6229,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, bt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = np.array(X[[col for col in X.columns if col!='PNL_0' and col!='PNL_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X1 = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6229, 13, 1), (6229,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X1.reshape(X1.shape[0],X1.shape[1],1)\n",
    "y = bt\n",
    "X1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como es un modelo de multiclasificación toca utilizar categorical_crossentropy y para esta hay que pasar y en formato (n_filas,n_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = to_categorical(y,num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6229, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y1.shape)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6229, 13, 1), (6229, 4))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, input_shape=(X1.shape[1],1)))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### para cuadrar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2686, 2741, 400, 402)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y==0),sum(y==1),sum(y==2),sum(y==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.97993433053630064, 6.7149999999999999, 6.6815920398009947)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y==0)/sum(y==0), sum(y==0)/sum(y==1), sum(y==0)/sum(y==2), sum(y==0)/sum(y==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_w = (y==0)*1 + (y==1)*0.97 + (y==2)*6.71 + (y==3)*6.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4402 - acc: 0.1775     \n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4422 - acc: 0.1730     \n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4532 - acc: 0.1578     \n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4437 - acc: 0.1807     \n",
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4426 - acc: 0.2033     \n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4397 - acc: 0.1657     \n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4412 - acc: 0.2065     \n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4404 - acc: 0.1815     \n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4423 - acc: 0.1792     \n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4436 - acc: 0.1725     \n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4419 - acc: 0.2000     \n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4458 - acc: 0.1975     \n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4435 - acc: 0.2185     \n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4396 - acc: 0.1547     \n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4447 - acc: 0.1923     \n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4450 - acc: 0.1648     \n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4390 - acc: 0.1890     \n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4424 - acc: 0.2030     \n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4449 - acc: 0.1842     \n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4473 - acc: 0.1955     \n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4426 - acc: 0.1815     \n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4483 - acc: 0.1890     \n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4463 - acc: 0.1837     \n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4441 - acc: 0.1795     \n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4440 - acc: 0.1760     \n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4455 - acc: 0.2000     \n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4441 - acc: 0.1857     \n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4435 - acc: 0.1867     \n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 3s - loss: 2.4426 - acc: 0.1880     \n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 3s - loss: 2.4426 - acc: 0.1765     \n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 3s - loss: 2.4498 - acc: 0.1950     \n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4439 - acc: 0.2295     \n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4406 - acc: 0.1940     - ETA: 0s - loss: 2.4158 -\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4420 - acc: 0.1898     \n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4446 - acc: 0.1928     \n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4467 - acc: 0.1542     \n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4437 - acc: 0.1717     \n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4428 - acc: 0.1620     \n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4445 - acc: 0.1820     \n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4432 - acc: 0.2127     \n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4461 - acc: 0.1657     \n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4413 - acc: 0.1847     \n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4406 - acc: 0.1700     \n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4428 - acc: 0.2145     \n",
      "Epoch 45/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4396 - acc: 0.1710     \n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4397 - acc: 0.1782     \n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4415 - acc: 0.1870     \n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4398 - acc: 0.1642     \n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4394 - acc: 0.1878     \n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4393 - acc: 0.1857     \n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4400 - acc: 0.1660     \n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4421 - acc: 0.1795     \n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4390 - acc: 0.1958     \n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4397 - acc: 0.1910     \n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4413 - acc: 0.1865     \n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4401 - acc: 0.1968     \n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4411 - acc: 0.1950     \n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4423 - acc: 0.1782     \n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4347 - acc: 0.2097     \n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4408 - acc: 0.2052     \n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4411 - acc: 0.1860     \n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4410 - acc: 0.2045     \n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4425 - acc: 0.2085     \n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4410 - acc: 0.1655     \n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 3s - loss: 2.4405 - acc: 0.2052     \n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4459 - acc: 0.1777     \n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4460 - acc: 0.1680     \n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4440 - acc: 0.1752     \n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4438 - acc: 0.1635     \n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4442 - acc: 0.1812     \n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4467 - acc: 0.1855     \n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4411 - acc: 0.1920     \n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4520 - acc: 0.1805     \n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4437 - acc: 0.1888     \n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4462 - acc: 0.2035     \n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4411 - acc: 0.2010     \n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4484 - acc: 0.1950     \n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4432 - acc: 0.1810     \n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4437 - acc: 0.1830     \n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4397 - acc: 0.1920     \n",
      "Epoch 81/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4502 - acc: 0.1340     \n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4493 - acc: 0.1010     \n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4459 - acc: 0.0968     \n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4448 - acc: 0.1207     \n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4441 - acc: 0.1920     \n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4407 - acc: 0.1657     \n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s - loss: 2.4444 - acc: 0.1773     \n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4450 - acc: 0.1140     \n",
      "Epoch 89/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4437 - acc: 0.1397     \n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4418 - acc: 0.1557     \n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4408 - acc: 0.1790     \n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4457 - acc: 0.1785     \n",
      "Epoch 93/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4461 - acc: 0.1685     \n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4443 - acc: 0.1613     \n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4445 - acc: 0.1923     \n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4430 - acc: 0.1625     \n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 1s - loss: 2.4435 - acc: 0.1517     \n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4399 - acc: 0.1985     \n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4458 - acc: 0.1860     \n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 2s - loss: 2.4395 - acc: 0.1593     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83192ba940>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1[:4000], y1[:4000], epochs=100, batch_size=32, class_weight={0:0.1,1:0.1,2:0.4,3:0.4},\n",
    "         sample_weight=s_w[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5984/6229 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pre = model.predict_classes(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 0:  49\n",
      "target 1:  1207\n",
      "target 2:  4398\n",
      "target 3:  575\n"
     ]
    }
   ],
   "source": [
    "print('target 0: ', sum(pre==0))\n",
    "print('target 1: ', sum(pre==1))\n",
    "print('target 2: ', sum(pre==2))\n",
    "print('target 3: ', sum(pre==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pnl_0 = X.PNL_0\n",
    "pnl_1 = X.PNL_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = sum((pre==1)*pnl_1 + (pre==0)*pnl_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.028910000000004432"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/step_validation.py\n",
    "def step_validationRNN(model, X, y, n_epochs, n_batch_size, class_weight, cv):\n",
    "    '''\n",
    "    Recibe el estimador,X,y, y un generador cv con el cual hace la validación\n",
    "    dependiendo que la configuración que este tenga\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    for index in cv:\n",
    "        pnl_1 = X.iloc[index[1]].PNL_1\n",
    "        pnl_0 = X.iloc[index[1]].PNL_0\n",
    "        X_pre = np.array(X.iloc[index[1]][[col for col in X.columns if col!='PNL_0' and col!='PNL_1']])\n",
    "        X_pre = X_pre.reshape(X_pre.shape[0],X_pre.shape[1],1)\n",
    "        \n",
    "        X1 = np.array(X.iloc[index[0]][[col for col in X.columns if col!='PNL_0' and col!='PNL_1']])\n",
    "        X1 = X1.reshape(X1.shape[0],X1.shape[1],1)\n",
    "        y1 = to_categorical(np.array(y[index[0]]))\n",
    "        \n",
    "        model.fit(X1, y1, epochs=n_epochs, batch_size=n_batch_size, class_weight=class_weight, verbose=0)\n",
    "        pre = model.predict_classes(X_pre)\n",
    "        r = sum((pre==1)*pnl_1 + (pre==0)*pnl_0)\n",
    "        \n",
    "        result.append(r)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/v_split.py\n",
    "# Se crea un generador \"v_split\" para utilizar como método de validación cruzada\n",
    "def v_splitRNN(X, n_bdtrain, n_bdtest, mday):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Hace un particionado del dataset, para tomar n_bdtrain días para entrenar\n",
    "    y n_bdtest para probar, además, mday representa el paso de día a correr.\n",
    "    X, dataframe, se necesita el indice de este para separar por días.\n",
    "    n_bdtrain, número de bussines day utilizados para train.\n",
    "    n_bdtest, número de bussines day utilizados para test.\n",
    "    mday, días a correr para cada validación.\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    start_day = 0\n",
    "    \n",
    "    #Divide el data set según días de train, test y cuanto se va moviendo\n",
    "    bussines_day = []\n",
    "    dates = pd.unique(X.index.date) #saco las fechas para luego tomar solo año-mes-día\n",
    "\n",
    "    for i in dates: bussines_day.append(date.__format__(i,'%Y-%m-%d')) #lista de los bussines day\n",
    "    \n",
    "    intervals = []\n",
    "    count = 0\n",
    "    for i in bussines_day:\n",
    "        f = len(X[i])-1 +count\n",
    "        intervals.append([count,f])\n",
    "        count = f+1\n",
    "    \n",
    "    for i in range(len(intervals)-n_bdtrain):\n",
    "        yield(np.arange(intervals[start_day:start_day+n_bdtrain][0][0],\n",
    "                        intervals[start_day:start_day+n_bdtrain][n_bdtrain-1][1]+1),\n",
    "              np.arange(intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][0][0],\n",
    "                        intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][n_bdtest-1][1]+1))\n",
    "    \n",
    "        start_day += mday\n",
    "        if start_day+n_bdtest > len(intervals)-n_bdtrain:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, input_shape=(X1.shape[1],1), return_sequences=True))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.add(LSTM(32))\n",
    "#model.add(Dense(10, activation=\"relu\", input_shape=(10,)))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "283/283 [==============================] - 0s     \n",
      "282/282 [==============================] - 0s     \n",
      "1/1 [==============================] - 0s- ETA: 0s\n",
      "282/282 [==============================] - 0s     \n",
      "282/282 [==============================] - 0s     \n",
      "1/1 [==============================] - 0s- ETA: 0s\n",
      "280/280 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "1/1 [==============================] - 0s- ETA: 0s\n",
      "23/23 [==============================] - 0sETA: 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "        0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "       -0.0049 , -0.01014, -0.01373, -0.02131, -0.01349, -0.01058,\n",
       "       -0.00172, -0.01477, -0.00813, -0.01124,  0.     ])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_validationRNN(model,X,y,n_epochs=200, n_batch_size=32,class_weight={0:0.06,1:0.06,2:0.44,3:0.44}\n",
    "                   ,cv=v_splitRNN(X,4,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00478304347826087"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array([ 0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
    "        0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
    "       -0.0049 , -0.01014, -0.01373, -0.02131, -0.01349, -0.01058,\n",
    "       -0.00172, -0.01477, -0.00813, -0.01124,  0.     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 15) (1, 15)\n",
      "(845, 15) (279, 15)\n",
      "(840, 15) (283, 15)\n",
      "(845, 15) (281, 15)\n",
      "(844, 15) (282, 15)\n",
      "(1125, 15) (280, 15)\n",
      "(1126, 15) (1, 15)\n",
      "(844, 15) (280, 15)\n",
      "(843, 15) (282, 15)\n",
      "(843, 15) (288, 15)\n",
      "(851, 15) (282, 15)\n",
      "(1132, 15) (283, 15)\n",
      "(1135, 15) (1, 15)\n",
      "(854, 15) (282, 15)\n",
      "(848, 15) (280, 15)\n",
      "(846, 15) (282, 15)\n",
      "(845, 15) (286, 15)\n",
      "(1130, 15) (284, 15)\n",
      "(1132, 15) (1, 15)\n",
      "(853, 15) (281, 15)\n",
      "(852, 15) (281, 15)\n",
      "(847, 15) (287, 15)\n",
      "(850, 15) (23, 15)\n"
     ]
    }
   ],
   "source": [
    "for i in v_splitRNN(X,4,1,1):\n",
    "    print(X.iloc[i[0]].shape, X.iloc[i[1]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/v_split.py\n",
    "# Se crea un generador \"v_split\" para utilizar como método de validación cruzada\n",
    "def v_split(X, n_bdtrain, n_bdtest, mday):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Hace un particionado del dataset, para tomar n_bdtrain días para entrenar\n",
    "    y n_bdtest para probar, además, mday representa el paso de día a correr.\n",
    "    X, dataframe, se necesita el indice de este para separar por días.\n",
    "    n_bdtrain, número de bussines day utilizados para train.\n",
    "    n_bdtest, número de bussines day utilizados para test.\n",
    "    mday, días a correr para cada validación.\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    start_day = 0\n",
    "    \n",
    "    #Divide el data set según días de train, test y cuanto se va moviendo\n",
    "    bussines_day = []\n",
    "    dates = pd.unique(X.index.date) #saco las fechas para luego tomar solo año-mes-día\n",
    "\n",
    "    for i in dates: bussines_day.append(date.__format__(i,'%Y-%m-%d')) #lista de los bussines day\n",
    "    \n",
    "    intervals = []\n",
    "    count = 0\n",
    "    for i in bussines_day:\n",
    "        f = len(X[i])-1 +count\n",
    "        intervals.append([count,f])\n",
    "        count = f+1\n",
    "    \n",
    "    for i in range(len(intervals)-n_bdtrain):\n",
    "        yield(np.arange(intervals[start_day:start_day+n_bdtrain][0][0],\n",
    "                        intervals[start_day:start_day+n_bdtrain][n_bdtrain-1][1]+1),\n",
    "              np.arange(intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][0][0],\n",
    "                        intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][n_bdtest-1][1]+1))\n",
    "    \n",
    "        start_day += mday\n",
    "        if start_day+n_bdtest > len(intervals)-n_bdtrain:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/step_validation.py\n",
    "def step_validationRNN(estimator, X, y, cv, n_epochs, n_batch_size):\n",
    "    '''\n",
    "    Recibe el estimador,X,y, y un generador cv con el cual hace la validación\n",
    "    dependiendo que la configuración que este tenga\n",
    "    '''\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    for index in cv:\n",
    "        estimator.fit(X.iloc[index[0]], y[index[0]], epochs=n_epochs, batch_size=n_batch_size)\n",
    "        result.append(estimator.score(X.iloc[index[1]], y[index[1]]))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
