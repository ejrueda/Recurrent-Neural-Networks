{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('../../data/TrueFX/EUR-USD/datos_procesados',\n",
    "                       index_col=0,infer_datetime_format=True, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:05:00</th>\n",
       "      <td>1.20094</td>\n",
       "      <td>1.20094</td>\n",
       "      <td>1.20011</td>\n",
       "      <td>1.20030</td>\n",
       "      <td>1.20115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:10:00</th>\n",
       "      <td>1.20030</td>\n",
       "      <td>1.20098</td>\n",
       "      <td>1.20011</td>\n",
       "      <td>1.20078</td>\n",
       "      <td>1.20123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:15:00</th>\n",
       "      <td>1.20073</td>\n",
       "      <td>1.20097</td>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:20:00</th>\n",
       "      <td>1.20030</td>\n",
       "      <td>1.20057</td>\n",
       "      <td>1.20025</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 00:25:00</th>\n",
       "      <td>1.20052</td>\n",
       "      <td>1.20053</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low      bid      ask\n",
       "2018-01-02 00:05:00  1.20094  1.20094  1.20011  1.20030  1.20115\n",
       "2018-01-02 00:10:00  1.20030  1.20098  1.20011  1.20078  1.20123\n",
       "2018-01-02 00:15:00  1.20073  1.20097  1.20032  1.20032  1.20094\n",
       "2018-01-02 00:20:00  1.20030  1.20057  1.20025  1.20051  1.20086\n",
       "2018-01-02 00:25:00  1.20052  1.20053  1.20048  1.20048  1.20083"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../code/PNLEstimatorWrapper.py\n",
    "%run ../../code/EUtilities.py\n",
    "EU = EUtilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = 12\n",
    "X, y_reg, bt = EU.build_dataset(data_set, window=window, bid_col='bid', binary_target=True, PNL=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>PNL_0</th>\n",
       "      <th>PNL_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:00:00</th>\n",
       "      <td>1.20030</td>\n",
       "      <td>1.20078</td>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>-0.00029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:05:00</th>\n",
       "      <td>1.20078</td>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>-0.00017</td>\n",
       "      <td>-0.00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:10:00</th>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:15:00</th>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>1.20146</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>-0.00019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:20:00</th>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>1.20146</td>\n",
       "      <td>1.20137</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>-0.00023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0        1        2        3        4        5  \\\n",
       "2018-01-02 01:00:00  1.20030  1.20078  1.20032  1.20051  1.20048  1.20061   \n",
       "2018-01-02 01:05:00  1.20078  1.20032  1.20051  1.20048  1.20061  1.20123   \n",
       "2018-01-02 01:10:00  1.20032  1.20051  1.20048  1.20061  1.20123  1.20134   \n",
       "2018-01-02 01:15:00  1.20051  1.20048  1.20061  1.20123  1.20134  1.20143   \n",
       "2018-01-02 01:20:00  1.20048  1.20061  1.20123  1.20134  1.20143  1.20133   \n",
       "\n",
       "                           6        7        8        9       10       11  \\\n",
       "2018-01-02 01:00:00  1.20123  1.20134  1.20143  1.20133  1.20141  1.20117   \n",
       "2018-01-02 01:05:00  1.20134  1.20143  1.20133  1.20141  1.20117  1.20099   \n",
       "2018-01-02 01:10:00  1.20143  1.20133  1.20141  1.20117  1.20099  1.20103   \n",
       "2018-01-02 01:15:00  1.20133  1.20141  1.20117  1.20099  1.20103  1.20146   \n",
       "2018-01-02 01:20:00  1.20141  1.20117  1.20099  1.20103  1.20146  1.20137   \n",
       "\n",
       "                       PNL_0    PNL_1  \n",
       "2018-01-02 01:00:00  0.00003 -0.00029  \n",
       "2018-01-02 01:05:00 -0.00017 -0.00011  \n",
       "2018-01-02 01:10:00 -0.00053  0.00030  \n",
       "2018-01-02 01:15:00  0.00004 -0.00019  \n",
       "2018-01-02 01:20:00  0.00012 -0.00023  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['open'] = data_set.filter(X.index,axis=0).open\n",
    "X['high'] = data_set.filter(X.index,axis=0).high\n",
    "X['low'] = data_set.filter(X.index,axis=0).low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>PNL_0</th>\n",
       "      <th>PNL_1</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:00:00</th>\n",
       "      <td>1.20030</td>\n",
       "      <td>1.20078</td>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>-0.00029</td>\n",
       "      <td>1.20139</td>\n",
       "      <td>1.20155</td>\n",
       "      <td>1.20114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:05:00</th>\n",
       "      <td>1.20078</td>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>-0.00017</td>\n",
       "      <td>-0.00011</td>\n",
       "      <td>1.20116</td>\n",
       "      <td>1.20125</td>\n",
       "      <td>1.20022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:10:00</th>\n",
       "      <td>1.20032</td>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20121</td>\n",
       "      <td>1.20072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:15:00</th>\n",
       "      <td>1.20051</td>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>1.20146</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>-0.00019</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>1.20159</td>\n",
       "      <td>1.20080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 01:20:00</th>\n",
       "      <td>1.20048</td>\n",
       "      <td>1.20061</td>\n",
       "      <td>1.20123</td>\n",
       "      <td>1.20134</td>\n",
       "      <td>1.20143</td>\n",
       "      <td>1.20133</td>\n",
       "      <td>1.20141</td>\n",
       "      <td>1.20117</td>\n",
       "      <td>1.20099</td>\n",
       "      <td>1.20103</td>\n",
       "      <td>1.20146</td>\n",
       "      <td>1.20137</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>-0.00023</td>\n",
       "      <td>1.20146</td>\n",
       "      <td>1.20150</td>\n",
       "      <td>1.20135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0        1        2        3        4        5  \\\n",
       "2018-01-02 01:00:00  1.20030  1.20078  1.20032  1.20051  1.20048  1.20061   \n",
       "2018-01-02 01:05:00  1.20078  1.20032  1.20051  1.20048  1.20061  1.20123   \n",
       "2018-01-02 01:10:00  1.20032  1.20051  1.20048  1.20061  1.20123  1.20134   \n",
       "2018-01-02 01:15:00  1.20051  1.20048  1.20061  1.20123  1.20134  1.20143   \n",
       "2018-01-02 01:20:00  1.20048  1.20061  1.20123  1.20134  1.20143  1.20133   \n",
       "\n",
       "                           6        7        8        9       10       11  \\\n",
       "2018-01-02 01:00:00  1.20123  1.20134  1.20143  1.20133  1.20141  1.20117   \n",
       "2018-01-02 01:05:00  1.20134  1.20143  1.20133  1.20141  1.20117  1.20099   \n",
       "2018-01-02 01:10:00  1.20143  1.20133  1.20141  1.20117  1.20099  1.20103   \n",
       "2018-01-02 01:15:00  1.20133  1.20141  1.20117  1.20099  1.20103  1.20146   \n",
       "2018-01-02 01:20:00  1.20141  1.20117  1.20099  1.20103  1.20146  1.20137   \n",
       "\n",
       "                       PNL_0    PNL_1     open     high      low  \n",
       "2018-01-02 01:00:00  0.00003 -0.00029  1.20139  1.20155  1.20114  \n",
       "2018-01-02 01:05:00 -0.00017 -0.00011  1.20116  1.20125  1.20022  \n",
       "2018-01-02 01:10:00 -0.00053  0.00030  1.20099  1.20121  1.20072  \n",
       "2018-01-02 01:15:00  0.00004 -0.00019  1.20103  1.20159  1.20080  \n",
       "2018-01-02 01:20:00  0.00012 -0.00023  1.20146  1.20150  1.20135  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Embedding, Bidirectional, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11893, 17), (11893,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, bt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = np.array(X[[col for col in X.columns if col!='PNL_0' and col!='PNL_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X1 = scaler.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11893, 1, 15), (11893,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X1.reshape(X1.shape[0],1,X1.shape[1])\n",
    "y = bt\n",
    "X1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(791, 754, 5175, 5173)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y==3), sum(y==2),sum(y==1), sum(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1470019342359768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "760/5170"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "como es un modelo de multiclasificación toca utilizar categorical_crossentropy y para esta hay que pasar y en formato (n_filas,n_clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = to_categorical(y,num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11893, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y1.shape)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11893, 1, 15), (11893, 4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "model = Sequential()\n",
    "model.add(LSTM(200,input_shape=(1,15)))\n",
    "#model.add(Bidirectional(LSTM(32), input_shape=(1,X1.shape[1])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### para cuadrar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.99961352657004832, 6.8607427055702921, 6.5398230088495577)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y==0)/sum(y==0), sum(y==0)/sum(y==1), sum(y==0)/sum(y==2), sum(y==0)/sum(y==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_w = (y==0)*.06 + (y==1)*.06 + (y==2)*.44 + (y==3)*.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1518 - acc: 0.1355     \n",
      "Epoch 2/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1517 - acc: 0.1359     \n",
      "Epoch 3/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1518 - acc: 0.1147     \n",
      "Epoch 4/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1517 - acc: 0.1113     \n",
      "Epoch 5/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1517 - acc: 0.1197     \n",
      "Epoch 6/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1516 - acc: 0.1100     \n",
      "Epoch 7/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1516 - acc: 0.1382     \n",
      "Epoch 8/10\n",
      "11893/11893 [==============================] - 1s - loss: 0.1516 - acc: 0.1184     \n",
      "Epoch 9/10\n",
      "11893/11893 [==============================] - 2s - loss: 0.1516 - acc: 0.1355     \n",
      "Epoch 10/10\n",
      "11893/11893 [==============================] - 2s - loss: 0.1516 - acc: 0.1208     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3262ffbbe0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X1, y1, epochs=10, batch_size=1000, class_weight={0:0.1,1:0.1,2:0.4,3:0.4},sample_weight=s_w)\n",
    "model.fit(X1, y1, epochs=10, batch_size=100, class_weight={0:0.06, 1:0.06, 2:0.44, 3:0.44})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11360/11893 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pre = model.predict_classes(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 0:  22\n",
      "target 1:  4743\n",
      "target 2:  0\n",
      "target 3:  7128\n"
     ]
    }
   ],
   "source": [
    "print('target 0: ', sum(pre==0))\n",
    "print('target 1: ', sum(pre==1))\n",
    "print('target 2: ', sum(pre==2))\n",
    "print('target 3: ', sum(pre==3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pnl_0 = X.PNL_0\n",
    "pnl_1 = X.PNL_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = sum((pre==1)*pnl_1 + (pre==0)*pnl_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22922999999997806"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('2mejor_modelo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(file='X_2018-1_2018-2',arr=X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/step_validation.py\n",
    "def step_validationRNN(model, X, y, n_epochs, n_batch_size, class_weight, cv):\n",
    "    '''\n",
    "    Recibe el estimador,X,y, y un generador cv con el cual hace la validación\n",
    "    dependiendo que la configuración que este tenga\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    for index in cv:\n",
    "        pnl_1 = X.iloc[index[1]].PNL_1\n",
    "        pnl_0 = X.iloc[index[1]].PNL_0\n",
    "        X_pre = np.array(X.iloc[index[1]][[col for col in X.columns if col!='PNL_0' and col!='PNL_1']])\n",
    "        X_pre = X_pre.reshape(X_pre.shape[0],X_pre.shape[1],1)\n",
    "        \n",
    "        X1 = np.array(X.iloc[index[0]][[col for col in X.columns if col!='PNL_0' and col!='PNL_1']])\n",
    "        X1 = X1.reshape(X1.shape[0],X1.shape[1],1)\n",
    "        y1 = to_categorical(np.array(y[index[0]]))\n",
    "        \n",
    "        model.fit(X1, y1, epochs=n_epochs, batch_size=n_batch_size, class_weight=class_weight, verbose=0)\n",
    "        pre = model.predict_classes(X_pre)\n",
    "        r = sum((pre==1)*pnl_1 + (pre==0)*pnl_0)\n",
    "        \n",
    "        result.append(r)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/v_split.py\n",
    "# Se crea un generador \"v_split\" para utilizar como método de validación cruzada\n",
    "def v_splitRNN(X, n_bdtrain, n_bdtest, mday):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Hace un particionado del dataset, para tomar n_bdtrain días para entrenar\n",
    "    y n_bdtest para probar, además, mday representa el paso de día a correr.\n",
    "    X, dataframe, se necesita el indice de este para separar por días.\n",
    "    n_bdtrain, número de bussines day utilizados para train.\n",
    "    n_bdtest, número de bussines day utilizados para test.\n",
    "    mday, días a correr para cada validación.\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    start_day = 0\n",
    "    \n",
    "    #Divide el data set según días de train, test y cuanto se va moviendo\n",
    "    bussines_day = []\n",
    "    dates = pd.unique(X.index.date) #saco las fechas para luego tomar solo año-mes-día\n",
    "\n",
    "    for i in dates: bussines_day.append(date.__format__(i,'%Y-%m-%d')) #lista de los bussines day\n",
    "    \n",
    "    intervals = []\n",
    "    count = 0\n",
    "    for i in bussines_day:\n",
    "        f = len(X[i])-1 +count\n",
    "        intervals.append([count,f])\n",
    "        count = f+1\n",
    "    \n",
    "    for i in range(len(intervals)-n_bdtrain):\n",
    "        yield(np.arange(intervals[start_day:start_day+n_bdtrain][0][0],\n",
    "                        intervals[start_day:start_day+n_bdtrain][n_bdtrain-1][1]+1),\n",
    "              np.arange(intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][0][0],\n",
    "                        intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][n_bdtest-1][1]+1))\n",
    "    \n",
    "        start_day += mday\n",
    "        if start_day+n_bdtest > len(intervals)-n_bdtrain:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, input_shape=(X1.shape[1],1), return_sequences=True))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.add(LSTM(32))\n",
    "#model.add(Dense(10, activation=\"relu\", input_shape=(10,)))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "283/283 [==============================] - 0s     \n",
      "282/282 [==============================] - 0s     \n",
      "1/1 [==============================] - 0s- ETA: 0s\n",
      "282/282 [==============================] - 0s     \n",
      "282/282 [==============================] - 0s     \n",
      "1/1 [==============================] - 0s- ETA: 0s\n",
      "280/280 [==============================] - 0s     \n",
      "286/286 [==============================] - 0s     \n",
      "1/1 [==============================] - 0s- ETA: 0s\n",
      "23/23 [==============================] - 0sETA: 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "        0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "       -0.0049 , -0.01014, -0.01373, -0.02131, -0.01349, -0.01058,\n",
       "       -0.00172, -0.01477, -0.00813, -0.01124,  0.     ])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_validationRNN(model,X,y,n_epochs=200, n_batch_size=32,class_weight={0:0.06,1:0.06,2:0.44,3:0.44}\n",
    "                   ,cv=v_splitRNN(X,4,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00478304347826087"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array([ 0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
    "        0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
    "       -0.0049 , -0.01014, -0.01373, -0.02131, -0.01349, -0.01058,\n",
    "       -0.00172, -0.01477, -0.00813, -0.01124,  0.     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1119, 15) (1, 15)\n",
      "(845, 15) (279, 15)\n",
      "(840, 15) (283, 15)\n",
      "(845, 15) (281, 15)\n",
      "(844, 15) (282, 15)\n",
      "(1125, 15) (280, 15)\n",
      "(1126, 15) (1, 15)\n",
      "(844, 15) (280, 15)\n",
      "(843, 15) (282, 15)\n",
      "(843, 15) (288, 15)\n",
      "(851, 15) (282, 15)\n",
      "(1132, 15) (283, 15)\n",
      "(1135, 15) (1, 15)\n",
      "(854, 15) (282, 15)\n",
      "(848, 15) (280, 15)\n",
      "(846, 15) (282, 15)\n",
      "(845, 15) (286, 15)\n",
      "(1130, 15) (284, 15)\n",
      "(1132, 15) (1, 15)\n",
      "(853, 15) (281, 15)\n",
      "(852, 15) (281, 15)\n",
      "(847, 15) (287, 15)\n",
      "(850, 15) (23, 15)\n"
     ]
    }
   ],
   "source": [
    "for i in v_splitRNN(X,4,1,1):\n",
    "    print(X.iloc[i[0]].shape, X.iloc[i[1]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/v_split.py\n",
    "# Se crea un generador \"v_split\" para utilizar como método de validación cruzada\n",
    "def v_split(X, n_bdtrain, n_bdtest, mday):\n",
    "\n",
    "    \"\"\"\"\n",
    "    Hace un particionado del dataset, para tomar n_bdtrain días para entrenar\n",
    "    y n_bdtest para probar, además, mday representa el paso de día a correr.\n",
    "    X, dataframe, se necesita el indice de este para separar por días.\n",
    "    n_bdtrain, número de bussines day utilizados para train.\n",
    "    n_bdtest, número de bussines day utilizados para test.\n",
    "    mday, días a correr para cada validación.\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import date\n",
    "    start_day = 0\n",
    "    \n",
    "    #Divide el data set según días de train, test y cuanto se va moviendo\n",
    "    bussines_day = []\n",
    "    dates = pd.unique(X.index.date) #saco las fechas para luego tomar solo año-mes-día\n",
    "\n",
    "    for i in dates: bussines_day.append(date.__format__(i,'%Y-%m-%d')) #lista de los bussines day\n",
    "    \n",
    "    intervals = []\n",
    "    count = 0\n",
    "    for i in bussines_day:\n",
    "        f = len(X[i])-1 +count\n",
    "        intervals.append([count,f])\n",
    "        count = f+1\n",
    "    \n",
    "    for i in range(len(intervals)-n_bdtrain):\n",
    "        yield(np.arange(intervals[start_day:start_day+n_bdtrain][0][0],\n",
    "                        intervals[start_day:start_day+n_bdtrain][n_bdtrain-1][1]+1),\n",
    "              np.arange(intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][0][0],\n",
    "                        intervals[n_bdtrain+start_day:n_bdtrain+start_day+n_bdtest][n_bdtest-1][1]+1))\n",
    "    \n",
    "        start_day += mday\n",
    "        if start_day+n_bdtest > len(intervals)-n_bdtrain:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../../code/step_validation.py\n",
    "def step_validationRNN(estimator, X, y, cv, n_epochs, n_batch_size):\n",
    "    '''\n",
    "    Recibe el estimador,X,y, y un generador cv con el cual hace la validación\n",
    "    dependiendo que la configuración que este tenga\n",
    "    '''\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    for index in cv:\n",
    "        estimator.fit(X.iloc[index[0]], y[index[0]], epochs=n_epochs, batch_size=n_batch_size)\n",
    "        result.append(estimator.score(X.iloc[index[1]], y[index[1]]))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
